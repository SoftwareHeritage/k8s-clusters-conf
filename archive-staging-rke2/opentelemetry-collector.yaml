# manually install (after installing the operator through helm)
# kubectl apply -f opentelemetry-collector.yaml
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: attributes-role
rules:
  - apiGroups:
      - ''
    resources:
      - pods
      - namespace
    verbs:
      - get
      - list
      - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: attributes-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: attributes-role
subjects:
  - kind: ServiceAccount
    name: attributes-account
    namespace: default
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: attributes-account
# ^ from: https://opentelemetry.io/blog/2022/k8s-otel-expose/#edge-cluster-configuration

---
apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: simplest
  namespace: default
spec:
  # mode: deployment  # default, as a standalone application (managed like other apps)
  mode: daemonset   # run as agent in kubernetes node (so each node has 1 collector)
  # mode: statefulset # like other too but names of pods becomes predictable
  # replicas: 3
  # mode: sidecar       # running alongside the applications to monitor
  #                     # (the application configurations must be slightly adapted)
  serviceAccount: attributes-account
  env:
    - name: KUBE_NODE_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: spec.nodeName

  # Required to let access to the filelog receiver
  volumeMounts:
    - mountPath: /var/log/pods
      name: varlogpods
  volumes:
    - name: varlogpods
      hostPath:
        path: /var/log/pods
        type: Directory

  config: |
    # extensions:
    #   # with port-forward, allows to display the pipeline status to see what's been
    #   # deployed
    #   zpages:
    #     endpoint: "0.0.0.0:8889"
    receivers:
      filelog/system:
        include:
          - /var/log/pods/*/*/*.log
        exclude:
          # Exclude 'swh*' namespaced logs
          - /var/log/pods/swh*_*/*/*.log
        start_at: beginning
        include_file_path: true
        include_file_name: false
        multiline:
          # as of now, starts as a date pattern (see parser-containerd below)
          line_start_pattern: '^[^ Z]+Z'
        operators:
        # Find out which log format is used to route it to proper parsers
        # Extract metadata from file path
        - id: extract_metadata_from_filepath
          type: regex_parser
          regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{32,36})\/(?P<container_name>[^\._]+)\/(?P<run_id>\d+)\.log$'
          parse_from: attributes["log.file.path"]
          parse_to: resource
        # Parse CRI-Containerd format
        - id: parser-containerd
          type: regex_parser
          regex: '^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr)( (?P<logtag>[^ ]*) (?P<message>.*)|.*)$'
          timestamp:
            parse_from: attributes.time
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
        # e.g. redis logs are "mostly" json, but no the ts entry is a timestamp that's
        # not adequately parsed. Type:"mapper_parsing_exception", Reason:"failed to
        # parse field [Attributes.ts] of type [date] in document...
        # - id: parser-json-message
        #   type: json_parser
        #   parse_from: attributes['message']
        #   parse_to: attributes
        #   if: attributes.message matches "^\\{"

      filelog/swh:
        include:
          # Only keep 'swh*' namespaces
          - /var/log/pods/swh*_*/*/*.log
        start_at: beginning
        include_file_path: true
        include_file_name: false
        multiline:
          # as of now, starts as a date pattern (see parser-containerd below)
          line_start_pattern: '^[^ Z]+Z'
        operators:
        # Find out which log format is used to route it to proper parsers
        # Extract metadata from file path
        - id: extract_metadata_from_filepath
          type: regex_parser
          regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{36})\/(?P<container_name>[^\._]+)\/(?P<run_id>\d+)\.log$'
          parse_from: attributes["log.file.path"]
          parse_to: resource
        # Parse CRI-Containerd format
        - id: parser-containerd
          type: regex_parser
          regex: '^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr)( (?P<logtag>[^ ]*) (?P<message>.*)|.*)$'
          timestamp:
            parse_from: attributes.time
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
        # then parse the json formatted message if any
        - id: parser-json-message
          type: json_parser
          parse_from: attributes['message']
          parse_to: attributes
          if: attributes.stream == 'stdout' && attributes.message matches "^\\{"
        # Those were an attempt to inline the json further but entries 'data.kwargs' and
        # 'return_value' are python dict and not json so we cannot parse them.
        # - id: parser-json-kwargs
        #   type: json_parser
        #   parse_from: attributes.data.kwargs
        #   parse_to: attributes
        #   if: attributes.stream == 'stdout' && attributes.data?.kwargs != nil
        # - id: parser-json-return-value
        #   type: json_parser
        #   parse_from: attributes.return_value
        #   parse_to: attributes
        #   if: attributes.stream == 'stdout' && attributes?.return_value != nil
        # This deals with basic key=value logs (it's not able to deal with "multi"
        # values those like key="this is a value" though, so prometheus, memcached logs
        # are not parsed so far)
        # - id: parse-key-value-message
        #   type: key_value_parser
        #   delimiter: "="
        #   pair_delimiter: " "
        #   parse_from: attributes['message']
        #   parse_to: attributes
        #   if: attributes.message matches "^ts="

      otlp:
        protocols:
          grpc:
          http:

    exporters:
      # Generalize the default logging (needs to be activated in the exporters)
      # logging/debug:
      #   loglevel: debug
      elasticsearch/swh-log:
        # can be replaced by using the env variable ELASTICSEARCH_URL
        endpoints:
          - http://esnode1.internal.softwareheritage.org:9200
          - http://esnode2.internal.softwareheritage.org:9200
          - http://esnode3.internal.softwareheritage.org:9200
          - http://esnode7.internal.softwareheritage.org:9200
        logs_index: staging-logs
      elasticsearch/system-log:
        # can be replaced by using the env variable ELASTICSEARCH_URL
        endpoints:
          - http://esnode1.internal.softwareheritage.org:9200
          - http://esnode2.internal.softwareheritage.org:9200
          - http://esnode3.internal.softwareheritage.org:9200
          - http://esnode7.internal.softwareheritage.org:9200
        logs_index: staging-system-logs

    processors:
      resource:
        attributes:
          - key: k8s.pod.name
            from_attribute: pod_name
            action: upsert
      k8sattributes:
        filter:
          node_from_env_var: KUBE_NODE_NAME
        passthrough: false
        extract:
          metadata:
            # from https://opentelemetry.io/docs/reference/specification/resource/semantic_conventions/k8s/
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
            - k8s.daemonset.name
            - k8s.job.name
            - k8s.cronjob.name
            # Desired properties (but not working for now
            # 2023/04/26 08:54:58 collector server run finished with error: failed to
            # build pipelines: failed to create "k8sattributes" processor, in pipeline
            # "logs/system": "k8s.cluster.name" (or "deployment.environment" ) is not a
            # supported metadata field
            # - k8s.cluster.name
            # - deployment.environment
        pod_association:
          - sources:
            - from: resource_attribute
              name: k8s.pod.name
          - sources:
            - from: connection
              name: k8s.pod.ip
          - sources:
            - from: resource_attribute
              name: k8s.pod.ip
      batch:
        send_batch_size: 1000
        # send_batch_size: 1
      attributes/insert:
        actions:
        - key: environment
          value: staging
          action: insert
        - key: cluster
          value: archive-staging-rke2
          action: insert
      attributes/clean-records:
        actions:
        - key: time
          action: delete
        - key: logtag
          action: delete
        - key: log
          action: delete
        - key: log.keyword
          action: delete
        - key: log.file.path
          action: delete
        - key: log.value
          action: delete

    service:
      # telemetry:
      #   logs:
      #     level: "debug"
      # extensions:
      #   # global extension
      #   - zpages
      pipelines:
        logs/system:
          receivers:
            - otlp
            - filelog/system
          processors:
            - resource
            - k8sattributes
            - batch
            - attributes/insert
            - attributes/clean-records
          exporters:
            - elasticsearch/system-log
            # - logging/debug
        logs/swh:
          receivers:
            - otlp
            - filelog/swh
          processors:
            - resource
            - k8sattributes
            - batch
            - attributes/insert
            - attributes/clean-records
          exporters:
            - elasticsearch/swh-log
            # - logging/debug
